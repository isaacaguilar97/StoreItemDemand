theme(aspect.ratio = 1)
lm_poly = lm(Density ~ Core +  poly(Depth,4),data = snow)
AIC(lm_poly)
lm_poly_int = lm(Density ~ Core *  poly(Depth,4),data = snow)
AIC(lm_poly_int)
lm_poly_int = lm(Density ~ Core *  poly(Depth,3),data = snow)
lm_poly = lm(Density ~ Core +  poly(Depth,3),data = snow)
lm_spline_linear = lm(Density ~ Core +
bs(Depth,knots = quantile(Depth,c(10)), degree = 3),
data = snow)
lm_spline_linear = lm(Density ~ Core +
bs(Depth,knots = 10, degree = 3),
data = snow)
lm_spline_cub = lm(Density ~ Core +
bs(Depth,knots = 10, degree = 3),
data = snow)
AIC(lm_spline_cub)
lm_spline_cub_int = lm(Density ~ Core *
bs(Depth,knots = 10, degree = 3),
data = snow)
lm_spline_cub_int = lm(Density ~ Core *
bs(Depth,knots = 10, degree = 3),
data = snow)
snow$pred.spline = predict(lm_spline_cub_int)
snow$resid.spline = lm_spline_cub_int$residuals
AIC(lm_spline_cub_int)
lm_snow = lm(Density ~ Depth * Core ,data = snow)
snow$pred.linear = predict(lm_snow)
snow$resid.linear = resid(lm_snow)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = resid.spline)) + geom_point() +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(splines)
snow = read_csv("snow_core.csv")
head(snow)
lm_prelim = lm(Density ~ Depth + Core ,data = snow)
summary(lm_prelim)
AIC(lm_prelim)
lm_snow = lm(Density ~ Depth * Core ,data = snow)
snow$pred.linear = predict(lm_snow)
snow$resid.linear = resid(lm_snow)
AIC(lm_snow)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = resid.linear)) + geom_point() +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
lm_poly = lm(Density ~ Core +  poly(Depth,3),data = snow)
AIC(lm_poly)
lm_poly_int = lm(Density ~ Core *  poly(Depth,3),data = snow)
AIC(lm_poly_int)
lm_spline_cub = lm(Density ~ Core +
bs(Depth,knots = 10, degree = 3),
data = snow)
AIC(lm_spline_cub)
lm_spline_cub_int = lm(Density ~ Core *
bs(Depth,knots = 10, degree = 3),
data = snow)
snow$pred.spline = predict(lm_spline_cub_int)
snow$resid.spline = lm_spline_cub_int$residuals
AIC(lm_spline_cub_int)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
lm_spline_cub_int = lm(Density ~ Core *
bs(Depth,knots = 10, degree = 3),
data = snow)
snow$pred.spline = predict(lm_spline_cub_int)
snow$resid.spline = lm_spline_cub_int$residuals
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = resid.spline)) + geom_point() +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
theme_bw() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
theme_bw() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) +
geom_point() +
theme_bw() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
library(tidyverse)
library(corrplot)  # for the correlation matrix
library(bestglm)  # for variable selection
library(car)  # for VIFs
library(MASS)  # for negative binomial regression
library(pscl)  # for zero-inflated regression
library(gridExtra)
bikes <- read_csv("Bikes.csv") %>%
mutate_if(is.character, as.factor)
bikes$yr <- as.factor(bikes$yr)
summary(bikes)
ggplot(data = bikes) +
geom_histogram(mapping = aes(x = cnt, y = ..density..),
binwidth = 100) +
theme_bw() +
theme(aspect.ratio = 1)
bikes_model <- bestglm(as.data.frame(bikes),
IC = "BIC",
method = "exhaustive",
TopModels = 1,
family = poisson)
summary(bikes_model$BestModel)
bikes_poisson <- glm(cnt ~ season + yr + holiday +
workingday + weathersit + temp + hum + windspeed,
data = bikes,
family = poisson(link = "log"))
summary(bikes_poisson)
#Temperature
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = temp)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
#Humidity
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = hum)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
#Windspeed
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = windspeed)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
# Use added variable plots for any continuous predictors you included in the
# model
avPlots(bikes_poisson, terms = ~ temp + hum + windspeed)
bikes.cooks <- data.frame("cooks.distance" = cooks.distance(bikes_poisson))
bikes.cooks$obs <- 1:nrow(bikes)
ggplot(data = bikes.cooks) +
geom_point(mapping = aes(x = obs, y = abs(cooks.distance))) +
geom_hline(mapping = aes(yintercept = 4/ length(obs)),
color = "red", linetype = "dashed") +  # for n > 30
geom_hline(mapping = aes(yintercept = 1),
color = "red", linetype = "dashed") +  # for n > 30
theme_bw() +
theme(aspect.ratio = 1)
bikes$cooksd <- cooks.distance(bikes_poisson)
bikes %>%
mutate(rowNum = row.names(bikes)) %>%  # save original row numbers
filter(cooksd > 4 / length(cooksd)) %>%  # select potential outliers
arrange(desc(cooksd))
library(tidyverse)
library(ggfortify)  # plot lm objects using ggplot instead of base R
library(car)  # needed for added-variable plots and dfbetas
library(corrplot)  # colored correlation matrix
# install.packages("devtools")
# devtools::install_github("thomasp85/patchwork")
library(patchwork)
FatComplete <- read_table("BodyFat.txt")
bodyfat<- FatComplete %>%
select(-row)
summary(bodyfat)
pairs(bodyfat, pch = 19)
round(cor(bodyfat), 2)
corrplot(cor(bodyfat), type = "upper")
bodyfat_lm <- lm(brozek ~ ., data = bodyfat)
summary(bodyfat_lm)
bodyfat$residuals <- bodyfat_lm$residuals
bodyfat_resid_vs_fit <- autoplot(bodyfat_lm, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
bodyfat_resid_vs_fit
plot4
## Loading Libraries
library(tidyverse)
library(vroom)
library(DataExplorer)
library(patchwork)
# Load data
bike <- vroom('./train.csv')
library(tidyverse)
library(vroom)
library(tidymodels)
library(naivebayes)
library(discrim)
library(DataExplorer)
library(bonsai)
library(lightgbm)
library(embed)
library(timetk)
library(patchwork)
library(modeltime) #Extensions of tidymodels to time series
library(timetk) #S
setwd('~/College/Stat348/StoreItemDemand')
trainSet <- vroom('./train.csv')
testSet <- vroom('./test.csv')
# Create 4 combinations of StoreItem
storeitem1 <- trainSet %>% filter(store == 1, item == 10)
storeitem2 <- trainSet %>% filter(store == 2, item == 9)
storeitem3 <- trainSet %>% filter(store == 3, item == 8)
storeitem4 <- trainSet %>% filter(store == 4, item == 7)
my_recipe <- recipe(sales~., data=storeitem4) %>%
step_date(date, features = c("dow", "month", "year", "week", "doy", "decimal")) %>%
step_holiday(date) %>%
step_range(date_doy, min = 0, max = pi) %>%
step_mutate(sinDOY = sin(date_doy), cosDOY = cos(date_doy)) %>%
# step_lag(date, lag = 365) %>%
# step_lag(date, lag = 30) %>%
# step_lag(date, lag = 7) %>%
# step_naomit(columnslag_365_date, lag_30_date, lag_7_date) %>%
step_rm('store', 'item')
# Split1
cv_split1 <- time_series_split(storeitem1, assess="3 months", cumulative = TRUE)
arima_recipe <- recipe(sales~., data=storeitem4) %>%
step_date(date, features = c("dow", "month", "year", "week", "doy", "decimal")) %>%
step_holiday(date) %>%
step_range(date_doy, min = 0, max = pi) %>%
step_mutate(sinDOY = sin(date_doy), cosDOY = cos(date_doy)) %>%
# step_lag(date, lag = 365) %>%
# step_lag(date, lag = 30) %>%
# step_lag(date, lag = 7) %>%
# step_naomit(columnslag_365_date, lag_30_date, lag_7_date) %>%
step_rm('store', 'item') # For the linear model part
S <- 365
arima_model <- arima_reg(seasonal_period=S,
non_seasonal_ar=5, # default max p to tune
non_seasona_ma=5, # default max q to tune
seasonal_ar=2, # default max P to tune
seasonal_ma=2, #default max Q to tune
non_seasonal_differences=2, # default max d to tune
seasonal_differences=2) %>% #default max D to tune
set_engine("auto.arima")
cv_split1 <- time_series_split(storeitem1, assess="3 months", cumulative = TRUE)
cv_split2 <- time_series_split(storeitem2, assess="3 months", cumulative = TRUE)
cv_split1
arima_recipe <- recipe(sales~., data=storeitem1) %>%
step_date(date, features = c("dow", "month", "year", "week", "doy", "decimal")) %>%
step_holiday(date) %>%
step_range(date_doy, min = 0, max = pi) %>%
step_mutate(sinDOY = sin(date_doy), cosDOY = cos(date_doy)) %>%
# step_lag(date, lag = 365) %>%
# step_lag(date, lag = 30) %>%
# step_lag(date, lag = 7) %>%
# step_naomit(columnslag_365_date, lag_30_date, lag_7_date) %>%
step_rm('store', 'item') # For the linear model part
S <- 365
arima_model <- arima_reg(seasonal_period=S,
non_seasonal_ar=5, # default max p to tune
non_seasona_ma=5, # default max q to tune
seasonal_ar=2, # default max P to tune
seasonal_ma=2, #default max Q to tune
non_seasonal_differences=2, # default max d to tune
seasonal_differences=2) %>% #default max D to tune
set_engine("auto.arima")
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data=training(cv_split1))
arima_model <- arima_reg(seasonal_period=S,
non_seasonal_ar=5, # default max p to tune
non_seasona_ma=5, # default max q to tune
seasonal_ar=2, # default max P to tune
seasonal_ma=2, #default max Q to tune
non_seasonal_differences=2, # default max d to tune
seasonal_differences=2) %>% #default max D to tune
set_engine("auto.arima")
arima_model <- arima_reg(seasonal_period=S,
non_seasonal_ar=5, # default max p to tune
non_seasonal_ma=5, # default max q to tune
seasonal_ar=2, # default max P to tune
seasonal_ma=2, #default max Q to tune
non_seasonal_differences=2, # default max d to tune
seasonal_differences=2) %>% #default max D to tune
set_engine("auto_arima")
arima_wf <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data=training(cv_split1))
arima_wf1 <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data=training(cv_split1))
arima_wf2 <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data=training(cv_split2))
cv_results1 <- modeltime_calibrate(arima_model,
new_data = testing(cv_split1))
cv_results1 <- modeltime_calibrate(arima_wf1,
new_data = testing(cv_split1))
cv_results2 <- modeltime_calibrate(arima_wf2,
new_data = testing(cv_split2))
p1 <- cv_results1 %>%
modeltime_forecast(
new_data = testing(cv_split1),
actual_data = storeitem1
) %>%
plot_modeltime_forecast(.interactive=TRUE)
p2 <- cv_results2 %>%
modeltime_forecast(
new_data = testing(cv_split2),
actual_data = storeitem2
) %>%
plot_modeltime_forecast(.interactive=TRUE)
es_fullfit1 <- cv_results1 %>%
modeltime_refit(data = storeitem1)
es_fullfit2 <- cv_results2 %>%
modeltime_refit(data = storeitem2)
p3 <- es_fullfit1 %>%
modeltime_forecast(h = "3 months", actual_data = storeitem1) %>%
plot_modeltime_forecast(.interactive=FALSE)
arima_recipe <- recipe(sales~., data=storeitem1) %>%
step_date(date, features = c("dow", "month", "year", "week", "doy", "decimal")) %>%
step_holiday(date) %>%
step_range(date_doy, min = 0, max = pi) %>%
step_mutate(sinDOY = sin(date_doy), cosDOY = cos(date_doy)) %>%
# step_lag(date, lag = 365) %>%
# step_lag(date, lag = 30) %>%
# step_lag(date, lag = 7) %>%
# step_naomit(columnslag_365_date, lag_30_date, lag_7_date) %>%
# step_rm('store', 'item') # For the linear model part
S <- 365
cv_split1 <- time_series_split(storeitem1, assess="3 months", cumulative = TRUE)
cv_split2 <- time_series_split(storeitem2, assess="3 months", cumulative = TRUE)
arima_recipe <- recipe(sales~., data=storeitem1) %>%
step_date(date, features = c("dow", "month", "year", "week", "doy", "decimal")) %>%
step_holiday(date) %>%
step_range(date_doy, min = 0, max = pi) %>%
step_mutate(sinDOY = sin(date_doy), cosDOY = cos(date_doy)) %>%
# step_lag(date, lag = 365) %>%
# step_lag(date, lag = 30) %>%
# step_lag(date, lag = 7) %>%
# step_naomit(columnslag_365_date, lag_30_date, lag_7_date) %>%
# step_rm('store', 'item') # For the linear model part
S <- 365
trainSet <- vroom('./train.csv')
testSet <- vroom('./test.csv')
storeitem1 <- trainSet %>% filter(store == 1, item == 10)
storeitem2 <- trainSet %>% filter(store == 2, item == 9)
storeitem3 <- trainSet %>% filter(store == 3, item == 8)
storeitem4 <- trainSet %>% filter(store == 4, item == 7)
cv_split1 <- time_series_split(storeitem1, assess="3 months", cumulative = TRUE)
cv_split2 <- time_series_split(storeitem2, assess="3 months", cumulative = TRUE)
arima_recipe <- recipe(sales~., data=storeitem1) %>%
step_date(date, features = c("dow", "month", "year", "week", "doy", "decimal")) %>%
step_holiday(date) %>%
step_range(date_doy, min = 0, max = pi) %>%
step_mutate(sinDOY = sin(date_doy), cosDOY = cos(date_doy))
# step_lag(date, lag = 365) %>%
# step_lag(date, lag = 30) %>%
# step_lag(date, lag = 7) %>%
# step_naomit(columnslag_365_date, lag_30_date, lag_7_date) %>%
# step_rm('store', 'item') # For the linear model part
S <- 365
arima_model <- arima_reg(seasonal_period=S,
non_seasonal_ar=5, # default max p to tune
non_seasonal_ma=5, # default max q to tune
seasonal_ar=2, # default max P to tune
seasonal_ma=2, #default max Q to tune
non_seasonal_differences=2, # default max d to tune
seasonal_differences=2) %>% #default max D to tune
set_engine("auto_arima")
arima_wf1 <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data=training(cv_split1))
arima_wf2 <- workflow() %>%
add_recipe(arima_recipe) %>%
add_model(arima_model) %>%
fit(data=training(cv_split2))
cv_results1 <- modeltime_calibrate(arima_wf1,
new_data = testing(cv_split1))
cv_results2 <- modeltime_calibrate(arima_wf2,
new_data = testing(cv_split2))
p1 <- cv_results1 %>%
modeltime_forecast(
new_data = testing(cv_split1),
actual_data = storeitem1
) %>%
plot_modeltime_forecast(.interactive=TRUE)
p2 <- cv_results2 %>%
modeltime_forecast(
new_data = testing(cv_split2),
actual_data = storeitem2
) %>%
plot_modeltime_forecast(.interactive=TRUE)
es_fullfit1 <- cv_results1 %>%
modeltime_refit(data = storeitem1)
es_fullfit2 <- cv_results2 %>%
modeltime_refit(data = storeitem2)
p3 <- es_fullfit1 %>%
modeltime_forecast(h = "3 months", actual_data = storeitem1) %>% # new_data = item
plot_modeltime_forecast(.interactive=FALSE)
p3 <- es_fullfit1 %>%
modeltime_forecast(actual_data = storeitem1) %>% # new_data = item
plot_modeltime_forecast(.interactive=FALSE)
p3 <- es_fullfit1 %>%
modeltime_forecast(new_data = storeitem1, actual_data = storeitem1) %>% # new_data = item
plot_modeltime_forecast(.interactive=FALSE)
p4 <- es_fullfit2 %>%
modeltime_forecast(new_data = storeitem1,actual_data = storeitem2) %>%
plot_modeltime_forecast(.interactive=FALSE)
plotly::subplot(p1,p3,p2,p4, nrows=2)
